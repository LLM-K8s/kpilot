# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: ai_service.proto
# Protobuf Python Version: 5.27.2
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    27,
    2,
    '',
    'ai_service.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10\x61i_service.proto\x12\nai_service\"(\n\x07Message\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\"\xb1\x01\n\x15\x43hatCompletionRequest\x12\r\n\x05model\x18\x01 \x01(\t\x12%\n\x08messages\x18\x02 \x03(\x0b\x32\x13.ai_service.Message\x12\x10\n\x08provider\x18\x03 \x01(\t\x12\x17\n\nmax_tokens\x18\x04 \x01(\x05H\x00\x88\x01\x01\x12\x18\n\x0btemperature\x18\x05 \x01(\x02H\x01\x88\x01\x01\x42\r\n\x0b_max_tokensB\x0e\n\x0c_temperature\"J\n\x16\x43hatCompletionResponse\x12\x0f\n\x07\x63ontent\x18\x01 \x01(\t\x12\r\n\x05model\x18\x02 \x01(\t\x12\x10\n\x08provider\x18\x03 \x01(\t2h\n\tAIService\x12[\n\x12GenerateCompletion\x12!.ai_service.ChatCompletionRequest\x1a\".ai_service.ChatCompletionResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ai_service_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_MESSAGE']._serialized_start=32
  _globals['_MESSAGE']._serialized_end=72
  _globals['_CHATCOMPLETIONREQUEST']._serialized_start=75
  _globals['_CHATCOMPLETIONREQUEST']._serialized_end=252
  _globals['_CHATCOMPLETIONRESPONSE']._serialized_start=254
  _globals['_CHATCOMPLETIONRESPONSE']._serialized_end=328
  _globals['_AISERVICE']._serialized_start=330
  _globals['_AISERVICE']._serialized_end=434
# @@protoc_insertion_point(module_scope)
